metadata:
  labels:
    pipeline_tag: "text-generation"
    chat: "true"

image: "rocm/vllm:rocm6.4.1_vllm_0.10.0_20250812"
model: "deepseek-ai/DeepSeek-V3.1"
served_model_name: "deepseek-ai/DeepSeek-V3.1"
gpus: 8
memory_per_gpu: 64 # Gi
cpu_per_gpu: 4

vllm_engine_args:
  max-model-len: "131072"
  enable-expert-parallel:

storage:
  ephemeral:
    quantity: 1024Gi
    storageClassName: mlstorage
    accessModes:
      - ReadWriteOnce
  dshm:
    sizeLimit: 64Gi
