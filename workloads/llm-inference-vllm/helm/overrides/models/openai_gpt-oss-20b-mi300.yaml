metadata:
  labels:
    pipeline_tag: "text-generation"
    chat: "true"

# reference: https://rocm.blogs.amd.com/ecosystems-and-partners/openai-day-0/README.html
image: "rocm/vllm-dev:open-mi300-08052025"

model: "openai/gpt-oss-20b"
gpus: 1
memory_per_gpu: 64 # Gi
cpu_per_gpu: 4

env_vars:
  VLLM_ROCM_USE_AITER: "1"
  VLLM_USE_AITER_UNIFIED_ATTENTION: "1"
  VLLM_ROCM_USE_AITER_MHA: "0"
  # Undo default vllm V0 and torch-tune settings
  VLLM_USE_V1: "1"
  PYTORCH_TUNABLEOP_ENABLED: "0"

vllm_engine_args:
  disable-log-requests:
  no-enable-prefix-caching:
  compilation-config: '{"full_cuda_graph": true}'
