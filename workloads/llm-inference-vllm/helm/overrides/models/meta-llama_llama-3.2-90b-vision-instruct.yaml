metadata:
  labels:
    pipeline_tag: "image-text-to-text"
    chat: "true"

model: "meta-llama/Llama-3.2-90B-Vision-Instruct"
served_model_name: "meta-llama/Llama-3.2-90B-Vision-Instruct"
gpus: 4
memory_per_gpu: 64 # Gi
cpu_per_gpu: 4

env_vars:
  HF_TOKEN:
    key: hf-token
    name: hf-token
