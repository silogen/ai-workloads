### General chart values ###
finetuningImage: rocm/verl:verl-0.3.0.post0_rocm6.2_vllm0.6.3

### Model ###
# either modelRemote OR modelName must be set
# to use a base model directly from Hugging Face, set modelName to the model identifier (e.g., "meta-llama/Llama-3.1-8B-Instruct")
modelName: ""
# for remote models to be loaded from MinIO, specify the path to the model in the remote bucket as modelRemote
modelRemote: ""

### Data ###
# either dataset OR datasetRemote must be set
# to use one of the pre-existing datasets, set dataset to the dataset identifier (e.g., "gsm8k")
# available datasets: "full_hh_rlhf", "geo3k", "gsm8k", "hellaswag", "math_dataset"
dataset: ""
# for remote datasets to be loaded from MinIO, specify the path to the model in the remote bucket as datasetRemote
# Note: the dataset should be processed and stored in a format compatible with VeRL (train.parquet, test.parquet)
datasetRemote: ""

# kaiwo settings (if enabled, use kaiwo CRDs to have kaiwo operator manage the workload)
kaiwo:
  enabled: false

# Use to add labels to the metadata of the resources created by this workload.
labels: {}

# Extra annotations such as an imagePullSecrets
imagePullSecrets: []
  # Example:
  # imagePullSecrets:
  #   - "regcred"

# Configure these to match the credentials in your cluster:
bucketStorageHost: http://minio.minio-tenant-default.svc.cluster.local:80
bucketCredentialsSecret:
  name: minio-credentials
  accessKeyKey: minio-access-key
  secretKeyKey: minio-secret-key

# Resources:
checkpointsReservedSize: 512Gi
storageClass: mlstorage # set this to use a specific storageClass for the storage.
finetuningGpus: 1
memoryPerGpu: 64
cpusPerGpu: 8
shmSize: 12Gi

### Model output path ###
checkpointsRemote: "" # Path where to sync checkpoints in bucket storage, format: bucketName/path/in/bucket
resumeFromCheckpoint: false  # Set to true to resume from the last checkpoint in checkpointsRemote (if available)

hfTokenSecret: {} # Optional secret reference that contains the HuggingFace token
# Example:
# hfTokenSecret:
#   name: hf-token
#   key: hf-token

verlConfig:
  trainer:
    logger: ['console']
    test_freq: 10
    save_freq: 10
    total_epochs: 1
