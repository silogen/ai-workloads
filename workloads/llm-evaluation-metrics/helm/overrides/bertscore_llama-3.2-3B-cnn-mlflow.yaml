model_inference_container:
  image: rocm/vllm-dev:nightly_main_20250430
  model: Llama-3.2-3B-Instruct
  model_path: meta-llama/Llama-3.2-3B-Instruct
evaluation_container:
  image: ghcr.io/silogen/evaluation-workloads-metrics-debug:v0.1
  use_data_subset: 3
storage:
  mlflow:
    server_uri: http://10.242.3.71:8082
    experiment_name: metrics-demo-experiment
    run_name: metrics-demo-run
