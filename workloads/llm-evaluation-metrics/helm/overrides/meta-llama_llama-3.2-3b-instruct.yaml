# Values file for running bertscore evaluation for Llama-3.2-3B on the default cnn-dailymail summarization dataset
general:
  job_name: evaluation-metrics-llama-3-2-3b
model_inference_container:
  gpu_count: 1
  model: Llama-3.2-3B-Instruct
  model_path: hf://meta-llama/Llama-3.2-3B-Instruct
evaluation_container:
  image: ghcr.io/silogen/evaluation-workloads-metrics:v0.1
  use_data_subset: 0 # Edit this for quick testing. Defines the number of documents used for evaluation. 0 means using the whole dataset
