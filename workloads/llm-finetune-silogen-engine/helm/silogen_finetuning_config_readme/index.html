
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Documentation for SiloGen AI Workloads Development">
      
      
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../../../llm-finetune-verl/helm/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.19">
    
    
      
        <title>Finetuning Config - SiloGen AI Workloads</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="black">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#finetuning-config-structure-and-parameters" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="SiloGen AI Workloads" class="md-header__button md-logo" aria-label="SiloGen AI Workloads" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SiloGen AI Workloads
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Finetuning Config
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="black"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="black"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="black"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/silogen/ai-workloads" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../docs/getting-started/" class="md-tabs__link">
        
  
  
    
  
  Getting Started

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../docs/tutorials/" class="md-tabs__link">
          
  
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../../docs/workloads/" class="md-tabs__link">
          
  
  
  Workloads

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../docs/contributing/" class="md-tabs__link">
        
  
  
    
  
  Contributing

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="SiloGen AI Workloads" class="md-nav__button md-logo" aria-label="SiloGen AI Workloads" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    SiloGen AI Workloads
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/silogen/ai-workloads" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/getting-started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/tutorials/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/tutorials/tutorial-00-prerequisites/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tutorial 0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/tutorials/tutorial-01-deliver-resources-and-finetune/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deliver Resources and Finetune
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/tutorials/tutorial-02-language-extension-finetune/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Language extension: Odia-finetuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/tutorials/tutorial-03-deliver-resources-and-run-megatron-cpt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Megatron-LM continuous pretraining of Llama-3.1-8B
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/tutorials/tutorial-04-deliver-llama70b-and-run-megatron-cpt-with-tp8-ddp2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Megatron-LM continuous pretraining of Llama-3.1-70B
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Workloads
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Workloads
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/workloads/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" checked>
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Workloads
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Workloads
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dev-chatui-aiaio/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    dev-chatui-aiaio
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dev-chatui-openwebui/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    dev-chatui-openwebui
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dev-text2image-comfyui/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    dev-text2image-comfyui
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dev-tracking-mlflow/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    dev-tracking-mlflow
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dev-workspace-jupyterlab/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    dev-workspace-jupyterlab
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dev-workspace-vscode/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    dev-workspace-vscode
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../download-data-to-bucket/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    download-data-to-bucket
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../download-huggingface-model-to-bucket/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    download-huggingface-model-to-bucket
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../download-wandb-model-to-bucket/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    download-wandb-model-to-bucket
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../k8s-namespace-setup/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    k8s-namespace-setup
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-deepspeed-estimate-ram-vram/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-deepspeed-estimate-ram-vram
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-evaluation-judge/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-evaluation-judge
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-evaluation-metrics/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-evaluation-metrics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-finetune-axolotl/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-finetune-axolotl
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-finetune-llama-factory/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-finetune-llama-factory
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2_16" checked>
        
          
          <label class="md-nav__link" for="__nav_4_2_16" id="__nav_4_2_16_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    llm-finetune-silogen-engine
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_2_16_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_2_16">
            <span class="md-nav__icon md-icon"></span>
            llm-finetune-silogen-engine
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Finetuning Config
    
  </span>
  

      </a>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-finetune-verl/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-finetune-verl
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-llamacpp-mi300x/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-llamacpp-mi300x
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-megatron-lm/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-megatron-lm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-ollama/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-ollama
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-openai-benchmark-guidellm/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-openai-benchmark-guidellm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-openai-benchmark-rocmblog/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-openai-benchmark-rocmblog
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-sglang/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-sglang
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-tgi/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-tgi
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-vllm/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-vllm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-vllm-benchmark-mad/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-vllm-benchmark-mad
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-inference-vllm-benchmark-rocmblog/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-inference-vllm-benchmark-rocmblog
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-megatron-ckpt-conversion/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-megatron-ckpt-conversion
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-pretraining-megatron-lm/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-pretraining-megatron-lm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../llm-pretraining-megatron-lm-ray/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    llm-pretraining-megatron-lm-ray
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../prepare-data-for-megatron-lm/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    prepare-data-for-megatron-lm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../rag-embedding-infinity/helm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    rag-embedding-infinity
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.dev/silogen/ai-workloads/blob/main/workloads/llm-finetune-silogen-engine/helm/silogen_finetuning_config_readme.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


<h1 id="finetuning-config-structure-and-parameters">Finetuning config structure and parameters<a class="headerlink" href="#finetuning-config-structure-and-parameters" title="Permanent link">&para;</a></h1>
<p>This document describes the structure of the finetuning configuration, and the parameters and values that can be defined there.</p>
<p>See the finetuning config section <a href="../overrides/llama-31-tiny-random-deepspeed-values.yaml">this config file</a> for an example of a valid configuration.
See the various sub-configs for their options. Additional properties are not allowed.</p>
<p><strong>Top-level properties:</strong></p>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>data_conf</td>
<td><code>object</code></td>
<td>✅</td>
<td><a href="#chattrainvalidconfig">ChatTrainValidConfig</a></td>
<td></td>
<td>The data input config</td>
</tr>
<tr>
<td>training_args</td>
<td><code>object</code></td>
<td>✅</td>
<td><a href="#silogentrainingarguments">SilogenTrainingArguments</a></td>
<td></td>
<td>Transformer TrainingArguments with some restrictions</td>
</tr>
<tr>
<td>batchsize_conf</td>
<td><code>object</code></td>
<td>✅</td>
<td><a href="#batchsizeconfig">BatchsizeConfig</a></td>
<td></td>
<td>Batch size configuration</td>
</tr>
<tr>
<td>peft_conf</td>
<td><code>object</code></td>
<td>✅</td>
<td><a href="#genericpeftconfig">GenericPeftConfig</a> and/or <a href="#nopeftconfig">NoPeftConfig</a> and/or <a href="#pretrainedpeftconfig">PretrainedPeftConfig</a></td>
<td></td>
<td>Adapter configuration</td>
</tr>
<tr>
<td>run_conf</td>
<td><code>object</code></td>
<td>✅</td>
<td><a href="#runconfig">RunConfig</a></td>
<td></td>
<td>Model related configuration</td>
</tr>
<tr>
<td>sft_args</td>
<td><code>object</code></td>
<td>✅</td>
<td><a href="#sftarguments">SFTArguments</a></td>
<td></td>
<td>SFT specific arguments</td>
</tr>
<tr>
<td>method</td>
<td><code>const</code></td>
<td></td>
<td><code>sft</code></td>
<td><code>"sft"</code></td>
<td></td>
</tr>
<tr>
<td>overrides</td>
<td><code>object</code></td>
<td></td>
<td><a href="#overrides">Overrides</a></td>
<td><code>{"lr_multiplier": 1.0, "lr_batch_size_scaling": "none"}</code></td>
<td>Override options to simplify the config interface</td>
</tr>
<tr>
<td>tracking</td>
<td><code>object</code> or <code>null</code></td>
<td></td>
<td><a href="#finetuningtrackingconfig">FinetuningTrackingConfig</a></td>
<td></td>
<td>MLFlow tracking configuration</td>
</tr>
<tr>
<td>quant_conf</td>
<td><code>object</code></td>
<td></td>
<td><a href="#bnbquantizationconfig">BnBQuantizationConfig</a> and/or <a href="#noquantizationconfig">NoQuantizationConfig</a></td>
<td><code>{"quantization_type": "no-quantization"}</code></td>
<td>Quantization configuration</td>
</tr>
</tbody>
</table>
<hr />
<h1 id="definitions">Definitions<a class="headerlink" href="#definitions" title="Permanent link">&para;</a></h1>
<h2 id="autosplitdatainput">AutoSplitDataInput<a class="headerlink" href="#autosplitdatainput" title="Permanent link">&para;</a></h2>
<p>Automatic validation split from the training data</p>
<h4 id="type-object">Type: <code>object</code><a class="headerlink" href="#type-object" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>type</td>
<td><code>const</code></td>
<td>✅</td>
<td><code>AUTO_SPLIT</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>data_type</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"ChatConversation"</code></td>
<td>Generally, the data_type is automatically set based on the experiment config method.</td>
</tr>
<tr>
<td>ratio</td>
<td><code>number</code></td>
<td></td>
<td>number</td>
<td><code>0.2</code></td>
<td>Ratio of the training data to use for validation</td>
</tr>
<tr>
<td>seed</td>
<td><code>integer</code></td>
<td></td>
<td>integer</td>
<td><code>1289525893</code></td>
<td>Seed for the random number generator for splitting</td>
</tr>
</tbody>
</table>
<h2 id="batchsizeconfig">BatchsizeConfig<a class="headerlink" href="#batchsizeconfig" title="Permanent link">&para;</a></h2>
<p>Config for determining the total batch size</p>
<p>Total batch size is the effective batch size for the complete training run. It is equal to
number of processes * per-device batch size * accumulation.</p>
<p>The maximum batch size per device is the maximum batch size that can be accommodated on a single device.
This mostly limited by the memory capacity of the device.</p>
<h4 id="type-object_1">Type: <code>object</code><a class="headerlink" href="#type-object_1" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>total_train_batch_size</td>
<td><code>integer</code></td>
<td>✅</td>
<td>integer</td>
<td>The total batch size for the training run</td>
</tr>
<tr>
<td>max_per_device_train_batch_size</td>
<td><code>integer</code></td>
<td>✅</td>
<td>integer</td>
<td>The maximum training batch size per device</td>
</tr>
<tr>
<td>per_device_eval_batch_size</td>
<td><code>integer</code> or <code>null</code></td>
<td></td>
<td>integer</td>
<td>The maximum eval batch size per device, if not given, will use same as training batch size</td>
</tr>
</tbody>
</table>
<h2 id="bnbquantizationconfig">BnBQuantizationConfig<a class="headerlink" href="#bnbquantizationconfig" title="Permanent link">&para;</a></h2>
<p>Bits and Bytes configuration</p>
<p>The options are from the BitsAndBytes config,
see: https://huggingface.co/docs/transformers/en/main_classes/quantization#transformers.BitsAndBytesConfig</p>
<h4 id="type-object_2">Type: <code>object</code><a class="headerlink" href="#type-object_2" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>quantization_type</td>
<td><code>const</code></td>
<td></td>
<td><code>bits-and-bytes</code></td>
<td><code>"bits-and-bytes"</code></td>
<td></td>
</tr>
<tr>
<td>load_in_8bit</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td></td>
</tr>
<tr>
<td>load_in_4bit</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td></td>
</tr>
<tr>
<td>llm_int8_threshold</td>
<td><code>number</code></td>
<td></td>
<td>number</td>
<td><code>6.0</code></td>
<td></td>
</tr>
<tr>
<td>llm_int8_skip_modules</td>
<td><code>array</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td></td>
</tr>
<tr>
<td>llm_int8_enable_fp32_cpu_offload</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td></td>
</tr>
<tr>
<td>llm_int8_has_fp16_weight</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td></td>
</tr>
<tr>
<td>bnb_4bit_compute_dtype</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td></td>
</tr>
<tr>
<td>bnb_4bit_quant_type</td>
<td><code>const</code></td>
<td></td>
<td><code>fp4</code> and/or <code>nf4</code></td>
<td><code>"fp4"</code></td>
<td></td>
</tr>
<tr>
<td>bnb_4bit_use_double_quant</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td></td>
</tr>
<tr>
<td>bnb_4bit_quant_storage</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="chattemplatename">ChatTemplateName<a class="headerlink" href="#chattemplatename" title="Permanent link">&para;</a></h2>
<p>Chat template to use.</p>
<h4 id="type-string">Type: <code>string</code><a class="headerlink" href="#type-string" title="Permanent link">&para;</a></h4>
<p><strong>Possible Values:</strong> <code>mistral-with-system</code> or <code>chat-ml</code> or <code>poro</code> or <code>keep-original</code> or <code>simplified-llama31</code></p>
<h2 id="chattrainvalidconfig">ChatTrainValidConfig<a class="headerlink" href="#chattrainvalidconfig" title="Permanent link">&para;</a></h2>
<p>Training time data configuration</p>
<p>Always defines some DataInput for training data and can include validation DataInput, though a trivial NoneDataInput
is also allowed for the validation side.</p>
<p>Additionally includes chat template and padding configurations, as those are part of the data input pipeline.</p>
<h4 id="type-object_3">Type: <code>object</code><a class="headerlink" href="#type-object_3" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>training_data</td>
<td><code>object</code></td>
<td>✅</td>
<td><a href="#concatenationdatainput">ConcatenationDataInput</a> and/or <a href="#weightedmixdatainput">WeightedMixDataInput</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>validation_data</td>
<td><code>object</code></td>
<td>✅</td>
<td><a href="#autosplitdatainput">AutoSplitDataInput</a> and/or <a href="#concatenationdatainput">ConcatenationDataInput</a> and/or <a href="#nonedatainput">NoneDataInput</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>chat_template_name</td>
<td><code>string</code></td>
<td></td>
<td><a href="#chattemplatename">ChatTemplateName</a></td>
<td><code>"mistral-with-system"</code></td>
<td></td>
</tr>
<tr>
<td>padding_side</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"right"</code></td>
<td>Padding side, right is usually right.</td>
</tr>
<tr>
<td>missing_pad_token_strategy</td>
<td><code>string</code></td>
<td></td>
<td><a href="#missingpadtokenstrategy">MissingPadTokenStrategy</a></td>
<td><code>"bos-repurpose"</code></td>
<td>See the MissingPadTokenStrategys for descriptions of the options</td>
</tr>
</tbody>
</table>
<h2 id="concatenationdatainput">ConcatenationDataInput<a class="headerlink" href="#concatenationdatainput" title="Permanent link">&para;</a></h2>
<p>A simple list of datasets</p>
<p>These are simply concatenated, the same as sampling all with equal weight.</p>
<p>The datasets themselves need to be in the finetuning supported JSONL formats.
For SFT this means lines:</p>
<div class="highlight"><pre><span></span><code>{&quot;messages&quot;: {&quot;content&quot;: &quot;string&quot;, &quot;role&quot;: &quot;string&quot;}}
</code></pre></div>
<p>For DPO this means lines of:</p>
<div class="highlight"><pre><span></span><code>{&quot;prompt_messages&quot;: {&quot;content&quot;: &quot;string&quot;, &quot;role&quot;: &quot;string&quot;}, &quot;chosen_messages&quot;: {&quot;content&quot;: &quot;string&quot;, &quot;role&quot;: &quot;string&quot;}, &quot;rejected_messages&quot;: {&quot;content&quot;: &quot;string&quot;, &quot;role&quot;: &quot;string&quot;}}
</code></pre></div>
<h4 id="type-object_4">Type: <code>object</code><a class="headerlink" href="#type-object_4" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>type</td>
<td><code>const</code></td>
<td>✅</td>
<td><code>CONCATENATION</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>datasets</td>
<td><code>array</code></td>
<td>✅</td>
<td><a href="#datasetdefinition">DatasetDefinition</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>data_type</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"ChatConversation"</code></td>
<td>Generally, the data_type is automatically set based on the experiment config method.</td>
</tr>
</tbody>
</table>
<h2 id="datasetdefinition">DatasetDefinition<a class="headerlink" href="#datasetdefinition" title="Permanent link">&para;</a></h2>
<p>Define how to load a dataset</p>
<h4 id="type-object_5">Type: <code>object</code><a class="headerlink" href="#type-object_5" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>path</td>
<td><code>string</code></td>
<td>✅</td>
<td>string</td>
<td>Local path to a JSONL file in the finetuning data format</td>
</tr>
</tbody>
</table>
<h2 id="finetuningtrackingconfig">FinetuningTrackingConfig<a class="headerlink" href="#finetuningtrackingconfig" title="Permanent link">&para;</a></h2>
<p>Settings that define how run details are logged</p>
<h4 id="type-object_6">Type: <code>object</code><a class="headerlink" href="#type-object_6" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>mlflow_server_uri</td>
<td><code>string</code></td>
<td>✅</td>
<td>string</td>
<td></td>
<td>MLflow server URI. Can be local path.</td>
</tr>
<tr>
<td>experiment_name</td>
<td><code>string</code></td>
<td>✅</td>
<td>string</td>
<td></td>
<td>Experiment name that is used for MLFlow tracking.</td>
</tr>
<tr>
<td>run_id</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td>Run id, to resume logging to previously started run.</td>
</tr>
<tr>
<td>run_name</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td>Run name, to give meaningful name to the run to be displayed in MLFlow UI. Used only when run_id is unspecified.</td>
</tr>
<tr>
<td>hf_mlflow_log_artifacts</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"False"</code></td>
<td>Whether to store model artifacts in MLFlow.</td>
</tr>
</tbody>
</table>
<h2 id="genericpeftconfig">GenericPeftConfig<a class="headerlink" href="#genericpeftconfig" title="Permanent link">&para;</a></h2>
<p>Config for any new initialized PEFT Adapter</p>
<p>See https://huggingface.co/docs/peft/tutorial/peft_model_config for the possible kwargs
and https://github.com/huggingface/peft/blob/v0.7.1/src/peft/utils/peft_types.py for the types.</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code>&gt;&gt;&gt; loaded_data = {&#39;peft_type&#39;:&#39;LORA&#39;, &#39;task_type&#39;: &#39;CAUSAL_LM&#39;,
...         &#39;peft_kwargs&#39;: {&#39;r&#39;: 32, &#39;target_modules&#39;: [&#39;v_proj&#39;]}}
&gt;&gt;&gt; generic_conf = GenericPeftConfig(**loaded_data)
&gt;&gt;&gt; # Then later in the code something like:
&gt;&gt;&gt; model = transformers.AutoModel.from_pretrained(&#39;hf-internal-testing/tiny-random-MistralModel&#39;)
&gt;&gt;&gt; peft.get_peft_model(model, generic_conf.get_peft_config())
PeftModelForCausalLM(
  (base_model): LoraModel(
    ...
  )
)
</code></pre></div>
<h4 id="type-object_7">Type: <code>object</code><a class="headerlink" href="#type-object_7" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>peft_type</td>
<td><code>string</code></td>
<td>✅</td>
<td><a href="#pefttype">PeftType</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>task_type</td>
<td><code>string</code></td>
<td></td>
<td><a href="#tasktype">TaskType</a></td>
<td><code>"CAUSAL_LM"</code></td>
<td></td>
</tr>
<tr>
<td>peft_kwargs</td>
<td><code>object</code></td>
<td></td>
<td>object</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="missingpadtokenstrategy">MissingPadTokenStrategy<a class="headerlink" href="#missingpadtokenstrategy" title="Permanent link">&para;</a></h2>
<p>Specifies the available missing pad token strategies.</p>
<p>We've shown in a small set of experiments that repurposing EOS can start to hurt performance
while the other options seem to work equally well.</p>
<p>Repurposing EOS is the default in many online sources, but it is actually a bad idea if we want to predict
EOS, as all the pad_token_ids get ignored in loss computation, and thus the model does not learn to predict
the end of the text. However, for models that have additional tokens for end of message, end of turn, etc.
this is not so dangerous.</p>
<p>Repurposing BOS is similar to repurposing EOS, but since we do not need to predict BOS, this may be more sensible.</p>
<p>Repurposing UNK can work with tokenizers that never produce UNKs in normal data (e.g. Mistral tokenizers should have
a byte fall-back so that everything can be tokenized).</p>
<p>UNK_CONVERT_TO_EOS uses a hack where the unk_token_id is initially used for padding, but in the collation phase the
input-side UNKs (padding) gets set to EOS, so that the input-side padding looks like EOS. On the output-side, the
UNKs (padding) still gets ignored. NOTE: This will leave the tokenizer's pad_token_id set to the unk_token_id; so
any subsequent use of the model where padding is involved should somehow explicitly set the pad_token_id again.</p>
<h4 id="type-string_1">Type: <code>string</code><a class="headerlink" href="#type-string_1" title="Permanent link">&para;</a></h4>
<p><strong>Possible Values:</strong> <code>eos-repurpose</code> or <code>bos-repurpose</code> or <code>unk-repurpose</code> or <code>unk-convert-to-eos</code></p>
<h2 id="modelarguments">ModelArguments<a class="headerlink" href="#modelarguments" title="Permanent link">&para;</a></h2>
<p>These are passed to AutoModelForCausalLM.from_pretrained</p>
<p>See parameter docstrings and help at:
https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained
See below in "Parameters for big model inference" too, it affects training too. Also note that this link takes you
to the transformers main branch version - be sure to compare with the installed version of transformers (that keeps
changing over time, and it is difficult to keep this docstring up to date, so we wanted to link to the latest here).</p>
<p>Some important parameters to consider are:</p>
<ul>
<li>device_map :
    A map that specifies where each submodule should go. It doesn’t need to be refined to each parameter/buffer
    name, once a given module name is inside, every submodule of it will be sent to the same device. If we only pass
    the device (e.g., "cpu", "cuda:1", "mps", or a GPU ordinal rank like 1) on which the model will be allocated,
    the device map will map the entire model to this device. Passing device_map = 0 means put the whole model on GPU
    0.</li>
<li>attn_implementation :
    The attention implementation to use in the model (if relevant). Can be any of "eager" (manual implementation of
    the attention), "sdpa" (using F.scaled_dot_product_attention), or "flash_attention_2" (using
    Dao-AILab/flash-attention). By default, if available, SDPA will be used for torch&gt;=2.1.1. The default is
    otherwise the manual "eager" implementation.</li>
</ul>
<p>NOTE:
    This does not include quantization_config. Quantization config is specified separately.</p>
<h4 id="type-object_8">Type: <code>object</code><a class="headerlink" href="#type-object_8" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>torch_dtype</td>
<td><code>const</code></td>
<td></td>
<td><code>auto</code></td>
<td><code>"auto"</code></td>
<td></td>
</tr>
<tr>
<td>device_map</td>
<td><code>object</code> or <code>string</code> or <code>null</code></td>
<td></td>
<td>object and/or string</td>
<td></td>
<td>Custom device map so that you can manually override the choices that HuggingFace would make. This can also be a string to specify "auto", "balanced_low_0", or "sequential".</td>
</tr>
<tr>
<td>max_memory</td>
<td><code>object</code> or <code>null</code></td>
<td></td>
<td>object</td>
<td></td>
<td></td>
</tr>
<tr>
<td>low_cpu_mem_usage</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td></td>
</tr>
<tr>
<td>attn_implementation</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td>Note: this can be set to "sdpa", "flash_attention_2", "eager".</td>
</tr>
<tr>
<td>offload_folder</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td></td>
</tr>
<tr>
<td>offload_state_dict</td>
<td><code>boolean</code> or <code>null</code></td>
<td></td>
<td>boolean</td>
<td></td>
<td>Default is True if offloading (otherwise no effect)</td>
</tr>
<tr>
<td>offload_buffers</td>
<td><code>boolean</code> or <code>null</code></td>
<td></td>
<td>boolean</td>
<td></td>
<td></td>
</tr>
<tr>
<td>use_cache</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>true</code></td>
<td>Saves generated hidden states to speed up generation, see: https://discuss.huggingface.co/t/what-is-the-purpose-of-use-cache-in-decoder/958 This is mutually exclusive with gradient_checkpointing.</td>
</tr>
<tr>
<td>cache_dir</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td></td>
</tr>
<tr>
<td>force_download</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td></td>
</tr>
<tr>
<td>local_files_only</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td></td>
</tr>
<tr>
<td>proxies</td>
<td><code>object</code> or <code>null</code></td>
<td></td>
<td>object</td>
<td></td>
<td></td>
</tr>
<tr>
<td>resume_download</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td></td>
</tr>
<tr>
<td>revision</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"main"</code></td>
<td></td>
</tr>
<tr>
<td>code_revision</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"main"</code></td>
<td></td>
</tr>
<tr>
<td>subfolder</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td></td>
</tr>
<tr>
<td>token</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td></td>
</tr>
<tr>
<td>use_safetensors</td>
<td><code>boolean</code> or <code>null</code></td>
<td></td>
<td>boolean</td>
<td></td>
<td></td>
</tr>
<tr>
<td>variant</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td></td>
</tr>
<tr>
<td>trust_remote_code</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td>Warning: if set to True, allows execution of downloaded remote code.</td>
</tr>
</tbody>
</table>
<h2 id="nopeftconfig">NoPeftConfig<a class="headerlink" href="#nopeftconfig" title="Permanent link">&para;</a></h2>
<p>A trivial config specifying that no peft is used</p>
<h4 id="type-object_9">Type: <code>object</code><a class="headerlink" href="#type-object_9" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>peft_type</td>
<td><code>const</code></td>
<td>✅</td>
<td><code>NO_PEFT</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="noquantizationconfig">NoQuantizationConfig<a class="headerlink" href="#noquantizationconfig" title="Permanent link">&para;</a></h2>
<p>A marker not to use quantization</p>
<h4 id="type-object_10">Type: <code>object</code><a class="headerlink" href="#type-object_10" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>quantization_type</td>
<td><code>const</code></td>
<td></td>
<td><code>no-quantization</code></td>
<td><code>"no-quantization"</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="nonedatainput">NoneDataInput<a class="headerlink" href="#nonedatainput" title="Permanent link">&para;</a></h2>
<p>A special type for not using data e.g. in validation</p>
<h4 id="type-object_11">Type: <code>object</code><a class="headerlink" href="#type-object_11" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>type</td>
<td><code>const</code></td>
<td>✅</td>
<td><code>NONE</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>data_type</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"ChatConversation"</code></td>
<td>Generally, the data_type is automatically set based on the experiment config method.</td>
</tr>
</tbody>
</table>
<h2 id="overrides">Overrides<a class="headerlink" href="#overrides" title="Permanent link">&para;</a></h2>
<p>Override options</p>
<p>These implement dynamic scaling for the learning rate.</p>
<h4 id="type-object_12">Type: <code>object</code><a class="headerlink" href="#type-object_12" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>lr_multiplier</td>
<td><code>number</code></td>
<td></td>
<td>number</td>
<td><code>1.0</code></td>
<td>Multiplier applied to the learning rate in the training_args</td>
</tr>
<tr>
<td>lr_batch_size_scaling</td>
<td><code>string</code></td>
<td></td>
<td><code>none</code> <code>sqrt</code> <code>linear</code></td>
<td><code>"none"</code></td>
<td>Scales the learning rate in the training_args by a factor derived from the total training batch size.             'none': No scaling.             'sqrt': Multiplies learning rate by square root of batch size (a classic scaling rule).             'linear': Multiplies learning rate by the batch size (a more modern scaling rule).</td>
</tr>
</tbody>
</table>
<h2 id="pefttype">PeftType<a class="headerlink" href="#pefttype" title="Permanent link">&para;</a></h2>
<p>Enum class for the different types of adapters in PEFT.</p>
<p>Supported PEFT types:
- PROMPT_TUNING
- MULTITASK_PROMPT_TUNING
- P_TUNING
- PREFIX_TUNING
- LORA
- ADALORA
- BOFT
- ADAPTION_PROMPT
- IA3
- LOHA
- LOKR
- OFT
- XLORA
- POLY
- LN_TUNING
- VERA
- FOURIERFT
- HRA</p>
<h4 id="type-string_2">Type: <code>string</code><a class="headerlink" href="#type-string_2" title="Permanent link">&para;</a></h4>
<p><strong>Possible Values:</strong> <code>PROMPT_TUNING</code> or <code>MULTITASK_PROMPT_TUNING</code> or <code>P_TUNING</code> or <code>PREFIX_TUNING</code> or <code>LORA</code> or <code>ADALORA</code> or <code>BOFT</code> or <code>ADAPTION_PROMPT</code> or <code>IA3</code> or <code>LOHA</code> or <code>LOKR</code> or <code>OFT</code> or <code>POLY</code> or <code>LN_TUNING</code> or <code>VERA</code> or <code>FOURIERFT</code> or <code>XLORA</code> or <code>HRA</code> or <code>VBLORA</code></p>
<h2 id="pretrainedpeftconfig">PretrainedPeftConfig<a class="headerlink" href="#pretrainedpeftconfig" title="Permanent link">&para;</a></h2>
<p>PEFT adapter uses the config and initialisation from a pretrained adapter</p>
<h4 id="type-object_13">Type: <code>object</code><a class="headerlink" href="#type-object_13" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>peft_type</td>
<td><code>const</code></td>
<td>✅</td>
<td><code>PRETRAINED_PEFT</code></td>
<td></td>
</tr>
<tr>
<td>name_or_path</td>
<td><code>string</code></td>
<td>✅</td>
<td>string</td>
<td>HF ID or path to the pretrained peft.</td>
</tr>
</tbody>
</table>
<h2 id="runconfig">RunConfig<a class="headerlink" href="#runconfig" title="Permanent link">&para;</a></h2>
<p>Experiment running configuration</p>
<h4 id="type-object_14">Type: <code>object</code><a class="headerlink" href="#type-object_14" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>model</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"/local_resources/basemodel"</code></td>
<td>Local path to model to be fine-tuned. Normally this should be /local_resources/basemodel</td>
</tr>
<tr>
<td>model_args</td>
<td><code>object</code></td>
<td></td>
<td><a href="#modelarguments">ModelArguments</a></td>
<td><code>{"torch_dtype": "auto", "device_map": "auto", "max_memory": null, "low_cpu_mem_usage": false, "attn_implementation": null, "offload_folder": null, "offload_state_dict": null, "offload_buffers": null, "use_cache": true, "cache_dir": null, "force_download": false, "local_files_only": false, "proxies": null, "resume_download": false, "revision": "main", "code_revision": "main", "subfolder": null, "token": null, "use_safetensors": null, "variant": null, "trust_remote_code": false}</code></td>
<td></td>
</tr>
<tr>
<td>tokenizer</td>
<td><code>string</code> or <code>null</code></td>
<td></td>
<td>string</td>
<td></td>
<td>Model HuggingFace ID, or path, or None to use the one associated with the model</td>
</tr>
<tr>
<td>use_fast_tokenizer</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>true</code></td>
<td>Use the Fast version of the tokenizer. The 'slow' version may be compatible with more features.</td>
</tr>
<tr>
<td>resume_from_checkpoint</td>
<td><code>boolean</code> or <code>string</code></td>
<td></td>
<td>boolean and/or string</td>
<td></td>
<td>Normally should be set to 'auto' to continue if a checkpoint exists.        Can set to True to always try to continue, False to never try, or a path to load from a specific path.</td>
</tr>
<tr>
<td>final_checkpoint_name</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"checkpoint-final"</code></td>
<td>Name of final checkpoint. Should be left as default</td>
</tr>
<tr>
<td>determinism</td>
<td><code>string</code></td>
<td></td>
<td><code>no</code> <code>half</code> <code>full</code></td>
<td><code>"no"</code></td>
<td>Set the level of determinism in implementations. Deterministic implementations are not always available,            and when they are, they are usually slower than their non-deterministic counterparts. Recommended for            debugging only.            'no': No determinism.            'half': Prefer deterministic implementations.            'full': Only fully deterministic implementations, error out on operations that only have non-deterministic                    implementations.</td>
</tr>
</tbody>
</table>
<h2 id="sftarguments">SFTArguments<a class="headerlink" href="#sftarguments" title="Permanent link">&para;</a></h2>
<p>Supervised fine-tuning arguments</p>
<h4 id="type-object_15">Type: <code>object</code><a class="headerlink" href="#type-object_15" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>max_seq_length</td>
<td><code>integer</code></td>
<td></td>
<td>integer</td>
<td><code>2048</code></td>
<td>Maximum length input sequence length. Longer sequences will be filtered out.</td>
</tr>
<tr>
<td>save_name_if_new_basemodel</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"checkpoint-new-basemodel"</code></td>
<td>If a new basemodel is saved, it will be saved with this name</td>
</tr>
<tr>
<td>train_on_completions_only</td>
<td><code>boolean</code></td>
<td></td>
<td>boolean</td>
<td><code>False</code></td>
<td>Only compute loss on the assistant's turns.</td>
</tr>
</tbody>
</table>
<h2 id="silogentrainingarguments">SilogenTrainingArguments<a class="headerlink" href="#silogentrainingarguments" title="Permanent link">&para;</a></h2>
<p>HuggingFace TrainingArguments as Config with additional SiloGen conventions</p>
<p>The list of training arguments is best available online (the version might not be up-to-date here):
https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments</p>
<p>The TrainingArguments object does a lot of things besides specifying the training configuaration options (e.g. it
has computed properties like true training batch size etc.)</p>
<h2 id="tasktype">TaskType<a class="headerlink" href="#tasktype" title="Permanent link">&para;</a></h2>
<p>Enum class for the different types of tasks supported by PEFT.</p>
<p>Overview of the supported task types:
- SEQ_CLS: Text classification.
- SEQ_2_SEQ_LM: Sequence-to-sequence language modeling.
- CAUSAL_LM: Causal language modeling.
- TOKEN_CLS: Token classification.
- QUESTION_ANS: Question answering.
- FEATURE_EXTRACTION: Feature extraction. Provides the hidden states which can be used as embeddings or features
  for downstream tasks.</p>
<h4 id="type-string_3">Type: <code>string</code><a class="headerlink" href="#type-string_3" title="Permanent link">&para;</a></h4>
<p><strong>Possible Values:</strong> <code>SEQ_CLS</code> or <code>SEQ_2_SEQ_LM</code> or <code>CAUSAL_LM</code> or <code>TOKEN_CLS</code> or <code>QUESTION_ANS</code> or <code>FEATURE_EXTRACTION</code></p>
<h2 id="weighteddatasetdefinition">WeightedDatasetDefinition<a class="headerlink" href="#weighteddatasetdefinition" title="Permanent link">&para;</a></h2>
<p>Define a dataset, with a weight for sampling</p>
<h4 id="type-object_16">Type: <code>object</code><a class="headerlink" href="#type-object_16" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>path</td>
<td><code>string</code></td>
<td>✅</td>
<td>string</td>
<td></td>
<td>Local path to a JSONL file in the finetuning data format</td>
</tr>
<tr>
<td>sampling_weight</td>
<td><code>number</code></td>
<td></td>
<td>number</td>
<td><code>1.0</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="weightedmixdatainput">WeightedMixDataInput<a class="headerlink" href="#weightedmixdatainput" title="Permanent link">&para;</a></h2>
<p>A list of datasets where each is sampled by a certain weight</p>
<p>These datasets are interleaved based on the sampling weights. The resulting dataset is fully precomputed, upto
the point where every single sample in every dataset gets picked. This means that with small sampling weights,
it can take a lot of draws to see every sample from a dataset and so the resulting dataset can be very large.</p>
<p>The datasets themselves need to be in the finetuning supported JSONL formats.
For SFT this means lines:</p>
<div class="highlight"><pre><span></span><code>{&quot;messages&quot;: {&quot;content&quot;: &quot;string&quot;, &quot;role&quot;: &quot;string&quot;}}
</code></pre></div>
<p>For DPO this means lines of:</p>
<div class="highlight"><pre><span></span><code>{&quot;prompt_messages&quot;: {&quot;content&quot;: &quot;string&quot;, &quot;role&quot;: &quot;string&quot;}, &quot;chosen_messages&quot;: {&quot;content&quot;: &quot;string&quot;, &quot;role&quot;: &quot;string&quot;}, &quot;rejected_messages&quot;: {&quot;content&quot;: &quot;string&quot;, &quot;role&quot;: &quot;string&quot;}}
</code></pre></div>
<h4 id="type-object_17">Type: <code>object</code><a class="headerlink" href="#type-object_17" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Required</th>
<th>Possible values</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>type</td>
<td><code>const</code></td>
<td>✅</td>
<td><code>PRECOMPUTE_WEIGHTED_MIX</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>datasets</td>
<td><code>array</code></td>
<td>✅</td>
<td><a href="#weighteddatasetdefinition">WeightedDatasetDefinition</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>data_type</td>
<td><code>string</code></td>
<td></td>
<td>string</td>
<td><code>"ChatConversation"</code></td>
<td>Generally, the data_type is automatically set based on the experiment config method.</td>
</tr>
<tr>
<td>seed</td>
<td><code>integer</code></td>
<td></td>
<td>integer</td>
<td><code>19851243</code></td>
<td>Seed for the random number generator for interleaving draws</td>
</tr>
</tbody>
</table>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "search.suggest", "search.highlight", "content.code.copy", "content.action.edit"], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.92b07e13.min.js"></script>
      
    
  </body>
</html>